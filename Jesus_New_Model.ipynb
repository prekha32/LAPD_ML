{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6cfa21",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e915e70",
   "metadata": {
    "id": "0e915e70"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34d8f8",
   "metadata": {},
   "source": [
    "## Data Collection and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a30c702",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "1a30c702",
    "outputId": "0dce1c19-78d8-4aa1-8e1e-328c568d267a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Crime_Data_from_2020_to_Present (2).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrime_Data_from_2020_to_Present (2).csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Carl\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Carl\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Carl\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Carl\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Carl\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Crime_Data_from_2020_to_Present (2).csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Crime_Data_from_2020_to_Present (2).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a432dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fe0ddf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "52fe0ddf",
    "outputId": "26fa6344-ac23-4fb8-ff06-863da1acb4b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Premis Cd</th>\n",
       "      <th>Premis Desc</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>Cross Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>101.0</td>\n",
       "      <td>STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 1402 0344</td>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>128.0</td>\n",
       "      <td>BUS STOP/LAYOVER (ALSO QUERY 124)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0344 1251</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0325 1501</td>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>405.0</td>\n",
       "      <td>CLOTHING STORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986869</th>\n",
       "      <td>0329 0400 0416</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>503.0</td>\n",
       "      <td>HOTEL</td>\n",
       "      <td>500.0</td>\n",
       "      <td>UNKNOWN WEAPON/OTHER WEAPON</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986870</th>\n",
       "      <td>0344</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>210.0</td>\n",
       "      <td>RESTAURANT/FAST FOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986871</th>\n",
       "      <td>1822 0334 0416 0445 0449 1202</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>102.0</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>308.0</td>\n",
       "      <td>STICK</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JEFFERSON                    BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>PARKING LOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986873 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Mocodes Vict Sex Vict Descent  Premis Cd  \\\n",
       "0                                 NaN        M            O      101.0   \n",
       "1                      1822 1402 0344        M            O      128.0   \n",
       "2                           0344 1251        X            X      502.0   \n",
       "3                           0325 1501        M            O      405.0   \n",
       "4                                 NaN      NaN          NaN      101.0   \n",
       "...                               ...      ...          ...        ...   \n",
       "986868                            NaN      NaN          NaN      101.0   \n",
       "986869                 0329 0400 0416        X            X      503.0   \n",
       "986870                           0344        M            B      210.0   \n",
       "986871  1822 0334 0416 0445 0449 1202        F            W      102.0   \n",
       "986872                            NaN      NaN          NaN      108.0   \n",
       "\n",
       "                                         Premis Desc  Weapon Used Cd  \\\n",
       "0                                             STREET             NaN   \n",
       "1                  BUS STOP/LAYOVER (ALSO QUERY 124)             NaN   \n",
       "2       MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)             NaN   \n",
       "3                                     CLOTHING STORE             NaN   \n",
       "4                                             STREET             NaN   \n",
       "...                                              ...             ...   \n",
       "986868                                        STREET             NaN   \n",
       "986869                                         HOTEL           500.0   \n",
       "986870                          RESTAURANT/FAST FOOD             NaN   \n",
       "986871                                      SIDEWALK           308.0   \n",
       "986872                                   PARKING LOT             NaN   \n",
       "\n",
       "                        Weapon Desc  Crm Cd 1  Crm Cd 2  Crm Cd 3  Crm Cd 4  \\\n",
       "0                               NaN     510.0     998.0       NaN       NaN   \n",
       "1                               NaN     330.0     998.0       NaN       NaN   \n",
       "2                               NaN     480.0       NaN       NaN       NaN   \n",
       "3                               NaN     343.0       NaN       NaN       NaN   \n",
       "4                               NaN     510.0       NaN       NaN       NaN   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "986868                          NaN     510.0       NaN       NaN       NaN   \n",
       "986869  UNKNOWN WEAPON/OTHER WEAPON     745.0       NaN       NaN       NaN   \n",
       "986870                          NaN     341.0       NaN       NaN       NaN   \n",
       "986871                        STICK     230.0       NaN       NaN       NaN   \n",
       "986872                          NaN     510.0       NaN       NaN       NaN   \n",
       "\n",
       "                           Cross Street  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "...                                 ...  \n",
       "986868                              NaN  \n",
       "986869                              NaN  \n",
       "986870                              NaN  \n",
       "986871  JEFFERSON                    BL  \n",
       "986872                              NaN  \n",
       "\n",
       "[986873 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Mocodes',\n",
    " 'Vict Sex',\n",
    " 'Vict Descent',\n",
    " 'Premis Cd',\n",
    " 'Premis Desc',\n",
    " 'Weapon Used Cd',\n",
    " 'Weapon Desc',\n",
    " 'Crm Cd 1',\n",
    " 'Crm Cd 2',\n",
    " 'Crm Cd 3',\n",
    " 'Crm Cd 4',\n",
    " 'Cross Street']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_crime_df = df\n",
    "# Saving the selected DataFrame to a CSV file\n",
    "reduced_crime_df.to_csv(\"reduced_crime_df.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'reduced_crime_df.csv' saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39dae1fa",
   "metadata": {
    "id": "39dae1fa"
   },
   "outputs": [],
   "source": [
    "df['Vict Sex'].fillna('X', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66287d5",
   "metadata": {
    "id": "e66287d5"
   },
   "outputs": [],
   "source": [
    "df['Vict Sex'].replace(['H', '-'], 'X', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05f58c4",
   "metadata": {
    "id": "b05f58c4"
   },
   "outputs": [],
   "source": [
    "df['Vict Descent'].replace('-', 'Unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2999a116",
   "metadata": {
    "id": "2999a116"
   },
   "outputs": [],
   "source": [
    "df[['Vict Descent', 'Weapon Used Cd', 'Weapon Desc']] = df[['Vict Descent', 'Weapon Used Cd', 'Weapon Desc']].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3975a7a1",
   "metadata": {
    "id": "3975a7a1"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Crm Cd 1'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5553ce42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "5553ce42",
    "outputId": "f0384fa2-06c1-4c52-a6ea-a5ee877afd48"
   },
   "outputs": [],
   "source": [
    "# Add case_solved column\n",
    "df['case_solved'] = df['Status Desc'].apply(lambda x: 'Not solved' if x == 'Invest Cont' else 'Solved')\n",
    "\n",
    "# Data preparation for victim_sex plot\n",
    "sex_solved_counts = df.groupby(['Vict Sex', 'case_solved']).size().unstack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e5b9f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0e5b9f2",
    "outputId": "1b617a92-396c-4f54-c600-7f91b1c5f49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas of min-25 percentage: ['Hollenbeck']\n",
      "Areas of 25-50 percentage: ['West Valley', 'Harbor', 'Devonshire', 'Topanga', 'Mission']\n",
      "Areas of 50-75 percentage: ['West LA', 'Van Nuys', 'Northeast']\n",
      "Areas of 75-max percentage: ['Central', '77th Street', 'Pacific', 'Southwest', 'Hollywood', 'Southeast', 'Newton', 'Olympic', 'Wilshire', 'Rampart', 'N Hollywood']\n",
      "----------------------------------------------------\n",
      "\n",
      "            count\n",
      "AREA NAME        \n",
      "Hollenbeck  36755\n",
      "             count\n",
      "AREA NAME         \n",
      "West Valley  41878\n",
      "Harbor       41070\n",
      "Devonshire   40874\n",
      "Topanga      40546\n",
      "Mission      40317\n",
      "           count\n",
      "AREA NAME       \n",
      "West LA    45272\n",
      "Van Nuys   42642\n",
      "Northeast  42576\n",
      "             count\n",
      "AREA NAME         \n",
      "Central      68959\n",
      "77th Street  61646\n",
      "Pacific      58881\n",
      "Southwest    56972\n",
      "Hollywood    52107\n",
      "Southeast    50101\n",
      "Newton       48917\n",
      "Olympic      48519\n",
      "Wilshire     47942\n",
      "Rampart      46520\n",
      "N Hollywood  46174\n"
     ]
    }
   ],
   "source": [
    "# assining variable as DataFrame\n",
    "area_crime_counts = df['AREA NAME'].value_counts().to_frame()\n",
    "\n",
    "area_under_25 = area_crime_counts[(area_crime_counts >= 29796) & (area_crime_counts < 37085)].dropna().index.to_list()\n",
    "area_under_50 = area_crime_counts[(area_crime_counts >= 37085) & (area_crime_counts < 42548)].dropna().index.to_list()\n",
    "area_under_75 = area_crime_counts[(area_crime_counts >= 42548) & (area_crime_counts < 45503)].dropna().index.to_list()\n",
    "area_over_75 = area_crime_counts[area_crime_counts >= 45503].dropna().index.to_list()\n",
    "\n",
    "print(f'Areas of min-25 percentage: {area_under_25}')\n",
    "print(f'Areas of 25-50 percentage: {area_under_50}')\n",
    "print(f'Areas of 50-75 percentage: {area_under_75}')\n",
    "print(f'Areas of 75-max percentage: {area_over_75}')\n",
    "\n",
    "print(\"----------------------------------------------------\\n\")\n",
    "\n",
    "print(area_crime_counts.loc[area_under_25])\n",
    "print(area_crime_counts.loc[area_under_50])\n",
    "print(area_crime_counts.loc[area_under_75])\n",
    "print(area_crime_counts.loc[area_over_75])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd9f85",
   "metadata": {
    "id": "60bd9f85"
   },
   "source": [
    "# Splicting data for features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6dfd0a",
   "metadata": {
    "id": "8d6dfd0a"
   },
   "outputs": [],
   "source": [
    "low_risk = area_crime_counts[area_crime_counts <= 42548].dropna().index.to_list()\n",
    "high_risk = area_crime_counts[area_crime_counts > 42548].dropna().index.to_list()\n",
    "\n",
    "# Add risk column\n",
    "df['Risk'] = df['AREA NAME'].apply(lambda area: 'Low risk' if area in low_risk else 'High risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51fcdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "# Add violent crime  column\n",
    "\n",
    "violent_codes = [231,230,220,624,622,623,860,235,627,814,922,110,822,921,830,236,626,910,920,435,113,625,122,121,210,810,815,251,250,821]\n",
    "for value in violent_codes:\n",
    "    df['Violent_Crime'] = (df['Crm Cd'] == value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833d708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "features = df[['AREA', 'Crm Cd', 'Vict Sex', 'Vict Descent', 'Violent_Crime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28ac1f8",
   "metadata": {
    "id": "c28ac1f8"
   },
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "df_cat = features.select_dtypes(include = 'object')\n",
    "df_num = features.select_dtypes(include = [np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04a8d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "\n",
    "for col in df_cat:\n",
    "    if col not in ['Violent_Crime']:\n",
    "        features[col] = Encoder.fit_transform(features[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e765f75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "8e765f75",
    "outputId": "b2c3a309-69c8-4e1c-e934-88c496537eb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Violent_Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AREA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>-0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crm Cd</th>\n",
       "      <td>-0.004759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043703</td>\n",
       "      <td>-0.010354</td>\n",
       "      <td>0.036064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vict Sex</th>\n",
       "      <td>-0.027656</td>\n",
       "      <td>-0.043703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487856</td>\n",
       "      <td>-0.011671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vict Descent</th>\n",
       "      <td>0.004416</td>\n",
       "      <td>-0.010354</td>\n",
       "      <td>0.487856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violent_Crime</th>\n",
       "      <td>-0.002373</td>\n",
       "      <td>0.036064</td>\n",
       "      <td>-0.011671</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AREA    Crm Cd  Vict Sex  Vict Descent  Violent_Crime\n",
       "AREA           1.000000 -0.004759 -0.027656      0.004416      -0.002373\n",
       "Crm Cd        -0.004759  1.000000 -0.043703     -0.010354       0.036064\n",
       "Vict Sex      -0.027656 -0.043703  1.000000      0.487856      -0.011671\n",
       "Vict Descent   0.004416 -0.010354  0.487856      1.000000      -0.009715\n",
       "Violent_Crime -0.002373  0.036064 -0.011671     -0.009715       1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################NEW#########################\n",
    "features.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec88a1f",
   "metadata": {},
   "source": [
    "## Taking Sample data for Predection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1baec186",
   "metadata": {
    "id": "1baec186"
   },
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "# Sample 300,000 rows from the DataFrame\n",
    "sampled_df = features.sample(n=300000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51a107af",
   "metadata": {},
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "X = sampled_df[['AREA', 'Crm Cd', 'Vict Sex', 'Vict Descent']]\n",
    "y = sampled_df['Violent_Crime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb22d52",
   "metadata": {},
   "source": [
    "## Scaling the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4580dba3",
   "metadata": {
    "id": "4580dba3"
   },
   "outputs": [],
   "source": [
    "################NEW#########################\n",
    "# import StandarScaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initialize the standard scalar\n",
    "Scale = StandardScaler()\n",
    "\n",
    "# scale all the numeric variables\n",
    "# standardize all the columns of the dataframe 'X_Scaled'\n",
    "X_Scaled = Scale.fit_transform(X)\n",
    "\n",
    "# create a dataframe of scaled numerical variables\n",
    "# pass the required column names to the parameter 'columns'\n",
    "X = pd.DataFrame(X_Scaled, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff56d9",
   "metadata": {},
   "source": [
    "## Splting Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81f73831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (240000, 4)\n",
      "y_train (240000,)\n",
      "X_test (60000, 4)\n",
      "y_test (60000,)\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "# split data into train subset and test subset\n",
    "# set 'random_state' to generate the same dataset each time you run the code\n",
    "# 'test_size' returns the proportion of data to be included in the testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 21, test_size = 0.2)\n",
    "\n",
    "# check the dimensions of the train & test subset using 'shape'\n",
    "# print dimension of train set\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "\n",
    "# print dimension of test set\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761044c4",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e577b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of our train data: 0.9993958333333334\n",
      "Accuracy score of our test data: 0.9994833333333333\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# train accuracy\n",
    "X_train_prediction  = model.predict(X_train)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction,y_train)\n",
    "\n",
    "print('Accuracy score of our train data:',train_data_accuracy)\n",
    "\n",
    "# test accuracy\n",
    "X_test_prediction  = model.predict(X_test)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, y_train)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction,y_test)\n",
    "\n",
    "print('Accuracy score of our test data:',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11345c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    239855\n",
      "           1       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           1.00    240000\n",
      "   macro avg       0.50      0.50      0.50    240000\n",
      "weighted avg       1.00      1.00      1.00    240000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "# You can also print out classification reports for more detailed performance analysis\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_train, X_train_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ea584f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     59969\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00     60000\n",
      "   macro avg       0.50      0.50      0.50     60000\n",
      "weighted avg       1.00      1.00      1.00     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "# You can also print out classification reports for more detailed performance analysis\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, X_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6098b",
   "metadata": {},
   "source": [
    "ANALYSIS of the ABOVE\n",
    "What Does This Mean?\n",
    "Training Accuracy: 0.9994 (99.94%):\n",
    "\n",
    "The model performs extremely well on the training dataset, correctly predicting almost all cases.\n",
    "Testing Accuracy: 0.9995 (99.95%):\n",
    "\n",
    "The model also performs very well on unseen data, indicating strong generalization.\n",
    "\n",
    "\n",
    "**************Imbalanced Dataset: If your dataset is imbalanced (e.g., one class dominates), such high accuracy might be misleading. \n",
    "\n",
    "\n",
    "Key Insights\n",
    "Class Imbalance:\n",
    "\n",
    "Class 0 (majority): 239,855 instances\n",
    "Class 1 (minority): 145 instances\n",
    "The dataset is highly imbalanced, with Class 0 dominating.\n",
    "Precision, Recall, F1-Score:\n",
    "\n",
    "Class 0:\n",
    "Precision, recall, and F1-score are all 1.00, meaning the model correctly identifies almost all Class 0 instances.\n",
    "Class 1:\n",
    "Precision, recall, and F1-score are all 0.00, indicating the model completely fails to identify Class 1 instances.\n",
    "Accuracy:\n",
    "\n",
    "The overall accuracy is 1.00 (99.94%), but this is misleading because it only reflects the correct predictions for the majority class (Class 0).\n",
    "Macro Average:\n",
    "\n",
    "The macro average for precision, recall, and F1-score is 0.50, which highlights the disparity in performance between the two classes.\n",
    "Weighted Average:\n",
    "\n",
    "Weighted metrics are dominated by the majority class, giving an illusion of good performance.\n",
    "\n",
    "How to Address This\n",
    "Resampling Techniques:\n",
    "\n",
    "Oversample the Minority Class: Add synthetic or duplicate samples for Class 1 using techniques like SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53668444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      "Violent_Crime\n",
      "0    239855\n",
      "1       145\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      "Violent_Crime\n",
      "0    239855\n",
      "1    239855\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution before and after SMOTE\n",
    "print(\"Before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"After SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d186552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of our train data: 0.9242563215275896\n",
      "Accuracy score of our test data: 0.8498\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "# train accuracy\n",
    "X_train_prediction  = model.predict(X_train_resampled)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction,y_train_resampled)\n",
    "\n",
    "print('Accuracy score of our train data:',train_data_accuracy)\n",
    "\n",
    "# test accuracy\n",
    "X_test_prediction  = model.predict(X_test)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, y_train_resampled)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction,y_test)\n",
    "\n",
    "print('Accuracy score of our test data:',test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd5503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92    239855\n",
      "           1       0.87      1.00      0.93    239855\n",
      "\n",
      "    accuracy                           0.92    479710\n",
      "   macro avg       0.93      0.92      0.92    479710\n",
      "weighted avg       0.93      0.92      0.92    479710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################NEW#########################\n",
    "# You can also print out classification reports for more detailed performance analysis\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_train_resampled, X_train_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91786961",
   "metadata": {},
   "source": [
    "analysis from above\n",
    "The Logistic Regression Classification Report you provided indicates a significant improvement in the performance of your model after applying SMOTE for oversampling the minority class. Here's a breakdown of the results:\n",
    "Key Metrics Breakdown\n",
    "Class 0 (Majority Class)\n",
    "\n",
    "Precision: 1.00\n",
    "Recall: 0.85\n",
    "F1-Score: 0.92\n",
    "Support: 239,855 instances\n",
    "This means the model is very precise when predicting Class 0 (i.e., correctly classifies instances of Class 0 most of the time), but it misses 15% of Class 0 cases (lower recall).\n",
    "\n",
    "Class 1 (Minority Class)\n",
    "\n",
    "Precision: 0.87\n",
    "Recall: 1.00\n",
    "F1-Score: 0.93\n",
    "Support: 239,855 instances\n",
    "For Class 1 (the minority class), the model now correctly classifies all instances (perfect recall), but there are still some errors in the predictions, reflected by the slightly lower precision (0.87).\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "Accuracy: 0.92 (92%)\n",
    "Overall, the model performs well on both classes, but there is a trade-off between precision and recall, especially for the majority class.\n",
    "Macro Average:\n",
    "\n",
    "Precision: 0.93\n",
    "Recall: 0.92\n",
    "F1-Score: 0.92\n",
    "The macro average calculates the average across all classes without taking class imbalance into account. It gives you a general idea of the model's overall performance across both classes.\n",
    "\n",
    "Weighted Average:\n",
    "\n",
    "Precision: 0.93\n",
    "Recall: 0.92\n",
    "F1-Score: 0.92\n",
    "The weighted average accounts for the imbalanced class distribution, giving more weight to the majority class. This is a more reflective measure of performance when the classes are imbalanced.\n",
    "\n",
    "Key Takeaways:\n",
    "Class 1 (minority class) now has perfect recall (1.00), which means it is fully captured by the model, but there’s a slight drop in precision (0.87). This indicates some false positives (Class 0 instances incorrectly predicted as Class 1).\n",
    "Class 0 (majority class) still has a very high precision (1.00), but its recall has dropped slightly to 0.85. This suggests the model might be missing some Class 0 instances (false negatives).\n",
    "Overall Accuracy: 92% is a solid performance, but the F1-scores of both classes indicate that there might still be room for improvement, especially in achieving a better balance between precision and recall."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
